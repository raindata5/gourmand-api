<!DOCTYPE html>
<html lang="en" data-bs-theme="dark">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" href="https://raw.githubusercontent.com/raindata5/gourmand-api/master/gourmandapiapp/templates/static/index.css"/>
    <link
    rel="icon"
    type="image/x-icon"
    href="https://th.bing.com/th/id/R.90e901ad5a648cfd2ed38519d7422247?rik=%2baBW82Y1%2bie5aA&riu=http%3a%2f%2fvignette2.wikia.nocookie.net%2fclashroyale%2fimages%2fb%2fb2%2fSad_Face.png%2frevision%2flatest%3fcb%3d20160706235335&ehk=L9Sl2BZCQB8AShTJ7Q1QDG%2flGrkbnrFnk1JHHlxA%2b7A%3d&risl=&pid=ImgRaw&r=0"
    />
    <link
    href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css"
    rel="stylesheet"
    integrity="sha384-T3c6CoIi6uLrA9TneNEoa7RxnatzjcDSCmG1MXxSR1GAsXEV/Dwwykc2MPK8M2HN"
    crossorigin="anonymous"
    />
    {% block head %}
    <title> Gourmand - Home </title>
    {% endblock %}
  </head>
  
  <body>
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark justify-content-between">

      <!-- <a class="navbar-brand" href="https://github.com/raindata5/gourmand-data-pipelines"> -->
        <a class="navbar-brand" href="/">
        <img src="https://raw.githubusercontent.com/raindata5/gourmand-api/master/gourmandapiapp/templates/static/gourmand_ai.png" width="50" height="50" class="d-inline-block align-top" alt="An AI generated image related to Gourmand">
        Gourmand
      </a>
    {% block nav_bar_custom %}

    <ul class="nav navbar-nav navbar-right mr-auto">
      {% if user_obj.email != 'Guest@gmail.com' %}
      <li class="nav-item">
        <a class="nav-link mr-sm-2" href="/login">Log Out {{user_obj.email}}</a>
      </li>
      {% else %}
      <li class="nav-item">
        <a class="nav-link mr-sm-2" href="/login">Log In, {{user_obj.email}}</a>
      </li>
      <li class="nav-item">
        <a class="nav-link mr-sm-2" href="/auth/register"> Register </a>
      </li>
      {% endif %}

    </ul>
    {% endblock %}

    </nav>

    {% block body %}
    <div>
      <h2>Business Data Architecture</h2>
      <p align="center">
        <a href="#overview">Overview</a> â€¢
        <a href="#data-architecture-diagram">Data Architecture Diagram</a> â€¢
        <a href="#data-visualization">Data Visualization</a> â€¢
        <a href="#main-concepts">Main Concepts</a> â€¢
        <a href="#prerequisites">Prerequisites</a> â€¢
        <a href="#set-up">Set-up</a> â€¢
        <a href="#where-to-go-from-here">Where to go from here</a>â€¢
        <a href="#contact">Contact</a> â€¢
      </p>
      <div>
        <h3>          
          <a id="overview">
            Overview
          </a>
        </h3>
        <p>
          This project looks to leverage multiple tools to create a data
          architecture that could help serve as the backend for a business and
          even the frontend (more on this in due time). While the initial focus
          was simply only creating a data pipeline to move the data from one
          source <em>x</em> to a data warehouse <em>y</em>
          to run some analyses, the project has evolved to include a number of
          supplementary technologies features partially due to problems that
          arose out of the blue. Fortunately while there may not always be meer
          solutions to everything there's always a nice trade-off i.e. compromise.
          To begin we'll extract data from 3 sources ,namely, the Census API , a web page via webscrape, and the Yelp API and push this to a Postgres database.
          Initially this will be used to simulate a source db using dbt to normalize the data as would be expected in most OLTP dbs.
          With that setup data from yelp will be pulled daily and inserted into this source db.
          From there the data will be extracted to an S3 Bucket which will serve as our de-facto data lake.
          Subsequently the data will be pulled from the S3 Bucket and ingested into some staging tables in Google Big Query ,that will serve as our data warehouse, where we'll make use of dbt to denormalize the data into a Snowflake Model.
          Once this is done some simple data validation checks will be carried out and we'll log these results and route them back to our Postgres db to create some metrics with them and send notifications via flask in the event of any issues.
          To orchestrate our recurring data workflow we'll use Apache Airflow with a Postgres Instance that is ran in a Docker container.
        </p>
          <blockquote class="blockquote text-center bg-secondary">
              <p>
                Note: Now the code has been updated to run Apache Airflow completely 
                in Docker with the CeleryExecutor ðŸ˜€. So now this provides more scalibility 
                if we plan on working with a multi-node setup. I just have yet to update the 
                directions in this code.
              </p>
          </blockquote>
          <p>
            
            Also using the FastAPI framework we'll be able to create an API on top of our source 
            database with Redis to cache certain responses.
          </p>

          <blockquote class="blockquote text-center bg-secondary">
            <p>
              Note: The API has been fully dockerized and integrated as such with the CI/CD pipeline.
            </p>
          </blockquote>
          <p>
          Since our goal is ultimately run some analyses we will then look to carry this out.
          There are also other plans to extend this project which can be seen in the following
          data architecture diagram.
        </p>
        <hr />
        <div>
          <h2>
          <a id="data-architecture-diagram">
              Data Architecture Diagram
            </a>
            </h2>
            <img src="https://github.com/raindata5/gourmand-data-pipelines/raw/master/images/data-pipeline-architecture.drawio.png">
            
        </div>
      </div>
      <!-- <p>{{request}}</p> -->
    </div>
    {% endblock %}
    <script src="/static/app.js" type="module"> </script> 

    <!-- <script>
      link_rv = document.querySelector('[data-id="resend-verification-link"]');
      link_rv.addEventListener(
        "click",
        (eve) => {
          window.alert('A new verification email has been sent to you by email :D')
          console.log(eve)
        }
      );
    </script> -->

    <script
      src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js"
      integrity="sha384-C6RzsynM9kWDrMNeT87bh95OGNyZPhcTNXj1NW7RuBCsyN/o0jlpcV8Qyq46cDfL"
      crossorigin="anonymous"
    ></script>
  </body>
</html>
